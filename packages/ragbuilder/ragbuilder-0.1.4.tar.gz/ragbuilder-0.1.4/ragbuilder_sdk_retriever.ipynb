{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Ingest Optimization Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'ragbuilder'...\n",
      "remote: Enumerating objects: 2154, done.\u001b[K\n",
      "remote: Counting objects: 100% (400/400), done.\u001b[K\n",
      "remote: Compressing objects: 100% (141/141), done.\u001b[K\n",
      "^Cceiving objects:  21% (467/2154), 11.86 MiB | 222.00 KiB/s \n",
      "fetch-pack: unexpected disconnect while reading sideband packet\n"
     ]
    }
   ],
   "source": [
    "# First clone the RAGBuilder repo\n",
    "!git clone https://github.com/KruxAI/ragbuilder.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ashwinaravind/.pyenv/versions/3.12.5/lib/python3.12/site-packages/pydantic/_internal/_fields.py:161: UserWarning: Field \"model_kwargs\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import getpass\n",
    "import yaml\n",
    "from ragbuilder.retriever.optimization import run_retriever_from_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_config = {\n",
    "    \"input_source\": \"sample_data.txt\",\n",
    "    \"test_dataset\": \"sample_questions.txt\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 11:43:25,037 - INFO - Starting optimization process\n",
      "[I 2024-10-23 11:43:25,038] A new study created in memory with name: data_ingest_1729663974944\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "921e69b9b7eb435aa86fb21a3255647a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 11:43:25,059 - INFO - Starting trial 1/10\n",
      "2024-10-23 11:43:25,062 - INFO - Trial parameters: {'input_source': 'sample_data.txt', 'test_dataset': 'sample_questions.txt', 'chunking_strategy': <ChunkingStrategy.RECURSIVE: 'RecursiveCharacterTextSplitter'>, 'chunk_overlap': 100, 'chunk_size': 200, 'embedding_model': EmbeddingConfig(type=<EmbeddingModel.HUGGINGFACE: 'huggingface'>, model='sentence-transformers/all-MiniLM-L6-v2', model_kwargs=None, custom_class=None), 'vector_database': VectorDBConfig(type=<VectorDatabase.FAISS: 'faiss'>, collection_name=None, persist_directory=None, client_settings=None, metadata=None, custom_class=None), 'top_k': 5, 'sampling_rate': None}\n",
      "/Users/ashwinaravind/.pyenv/versions/3.12.5/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "/Users/ashwinaravind/.pyenv/versions/3.12.5/lib/python3.12/site-packages/langchain_core/vectorstores/base.py:784: UserWarning: Relevance scores must be between 0 and 1, got [(Document(metadata={'source': 'sample_data.txt'}, page_content=\"It contains multiple sentences to demonstrate chunking. We'll use this to test our parser, chunker, embedder, and indexer components. The goal is to ensure that our pipeline works end-to-end with a\"), 0.19970282783319682), (Document(metadata={'source': 'sample_data.txt'}, page_content=\"# sample_data.txt This is a sample document for testing the RAGBuilder data ingestion pipeline. It contains multiple sentences to demonstrate chunking. We'll use this to test our parser, chunker,\"), 0.01182701286230714), (Document(metadata={'source': 'sample_data.txt'}, page_content='embedder, and indexer components. The goal is to ensure that our pipeline works end-to-end with a simple configuration.'), -0.07464592910858525)]\n",
      "  warnings.warn(\n",
      "/Users/ashwinaravind/.pyenv/versions/3.12.5/lib/python3.12/site-packages/langchain_core/vectorstores/base.py:784: UserWarning: Relevance scores must be between 0 and 1, got [(Document(metadata={'source': 'sample_data.txt'}, page_content=\"It contains multiple sentences to demonstrate chunking. We'll use this to test our parser, chunker, embedder, and indexer components. The goal is to ensure that our pipeline works end-to-end with a\"), 0.1496935690262926), (Document(metadata={'source': 'sample_data.txt'}, page_content=\"# sample_data.txt This is a sample document for testing the RAGBuilder data ingestion pipeline. It contains multiple sentences to demonstrate chunking. We'll use this to test our parser, chunker,\"), 0.04391534738868219), (Document(metadata={'source': 'sample_data.txt'}, page_content='embedder, and indexer components. The goal is to ensure that our pipeline works end-to-end with a simple configuration.'), -0.16164225064428583)]\n",
      "  warnings.warn(\n",
      "/Users/ashwinaravind/.pyenv/versions/3.12.5/lib/python3.12/site-packages/langchain_core/vectorstores/base.py:784: UserWarning: Relevance scores must be between 0 and 1, got [(Document(metadata={'source': 'sample_data.txt'}, page_content=\"It contains multiple sentences to demonstrate chunking. We'll use this to test our parser, chunker, embedder, and indexer components. The goal is to ensure that our pipeline works end-to-end with a\"), -0.02575710212249449), (Document(metadata={'source': 'sample_data.txt'}, page_content='embedder, and indexer components. The goal is to ensure that our pipeline works end-to-end with a simple configuration.'), -0.03478630577268049), (Document(metadata={'source': 'sample_data.txt'}, page_content=\"# sample_data.txt This is a sample document for testing the RAGBuilder data ingestion pipeline. It contains multiple sentences to demonstrate chunking. We'll use this to test our parser, chunker,\"), -0.13874462649159036)]\n",
      "  warnings.warn(\n",
      "2024-10-23 11:43:43,439 - INFO - Starting trial 2/10\n",
      "2024-10-23 11:43:43,440 - INFO - Trial parameters: {'input_source': 'sample_data.txt', 'test_dataset': 'sample_questions.txt', 'chunking_strategy': <ChunkingStrategy.RECURSIVE: 'RecursiveCharacterTextSplitter'>, 'chunk_overlap': 100, 'chunk_size': 200, 'embedding_model': EmbeddingConfig(type=<EmbeddingModel.HUGGINGFACE: 'huggingface'>, model='sentence-transformers/all-MiniLM-L6-v2', model_kwargs=None, custom_class=None), 'vector_database': VectorDBConfig(type=<VectorDatabase.FAISS: 'faiss'>, collection_name=None, persist_directory=None, client_settings=None, metadata=None, custom_class=None), 'top_k': 5, 'sampling_rate': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2024-10-23 11:43:43,438] Trial 0 finished with value: -0.0033819396699064064 and parameters: {'chunking_strategy': <ChunkingStrategy.RECURSIVE: 'RecursiveCharacterTextSplitter'>, 'chunk_size': 200}. Best is trial 0 with value: -0.0033819396699064064.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ashwinaravind/.pyenv/versions/3.12.5/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "2024-10-23 11:43:46,607 - INFO - Starting trial 3/10\n",
      "2024-10-23 11:43:46,608 - INFO - Trial parameters: {'input_source': 'sample_data.txt', 'test_dataset': 'sample_questions.txt', 'chunking_strategy': <ChunkingStrategy.CHARACTER: 'CharacterTextSplitter'>, 'chunk_overlap': 100, 'chunk_size': 500, 'embedding_model': EmbeddingConfig(type=<EmbeddingModel.HUGGINGFACE: 'huggingface'>, model='sentence-transformers/all-MiniLM-L6-v2', model_kwargs=None, custom_class=None), 'vector_database': VectorDBConfig(type=<VectorDatabase.FAISS: 'faiss'>, collection_name=None, persist_directory=None, client_settings=None, metadata=None, custom_class=None), 'top_k': 5, 'sampling_rate': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2024-10-23 11:43:46,606] Trial 1 finished with value: -0.0033819396699064064 and parameters: {'chunking_strategy': <ChunkingStrategy.RECURSIVE: 'RecursiveCharacterTextSplitter'>, 'chunk_size': 200}. Best is trial 0 with value: -0.0033819396699064064.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ashwinaravind/.pyenv/versions/3.12.5/lib/python3.12/site-packages/langchain_core/vectorstores/base.py:784: UserWarning: Relevance scores must be between 0 and 1, got [(Document(metadata={'source': 'sample_data.txt'}, page_content=\"# sample_data.txt This is a sample document for testing the RAGBuilder data ingestion pipeline. It contains multiple sentences to demonstrate chunking. We'll use this to test our parser, chunker, embedder, and indexer components. The goal is to ensure that our pipeline works end-to-end with a simple configuration.\"), -0.021253205596923452)]\n",
      "  warnings.warn(\n",
      "/Users/ashwinaravind/.pyenv/versions/3.12.5/lib/python3.12/site-packages/langchain_core/vectorstores/base.py:784: UserWarning: Relevance scores must be between 0 and 1, got [(Document(metadata={'source': 'sample_data.txt'}, page_content=\"# sample_data.txt This is a sample document for testing the RAGBuilder data ingestion pipeline. It contains multiple sentences to demonstrate chunking. We'll use this to test our parser, chunker, embedder, and indexer components. The goal is to ensure that our pipeline works end-to-end with a simple configuration.\"), -0.01901613517166223)]\n",
      "  warnings.warn(\n",
      "/Users/ashwinaravind/.pyenv/versions/3.12.5/lib/python3.12/site-packages/langchain_core/vectorstores/base.py:784: UserWarning: Relevance scores must be between 0 and 1, got [(Document(metadata={'source': 'sample_data.txt'}, page_content=\"# sample_data.txt This is a sample document for testing the RAGBuilder data ingestion pipeline. It contains multiple sentences to demonstrate chunking. We'll use this to test our parser, chunker, embedder, and indexer components. The goal is to ensure that our pipeline works end-to-end with a simple configuration.\"), -0.08075376610108687)]\n",
      "  warnings.warn(\n",
      "2024-10-23 11:43:50,497 - INFO - Starting trial 4/10\n",
      "2024-10-23 11:43:50,498 - INFO - Trial parameters: {'input_source': 'sample_data.txt', 'test_dataset': 'sample_questions.txt', 'chunking_strategy': <ChunkingStrategy.RECURSIVE: 'RecursiveCharacterTextSplitter'>, 'chunk_overlap': 100, 'chunk_size': 300, 'embedding_model': EmbeddingConfig(type=<EmbeddingModel.HUGGINGFACE: 'huggingface'>, model='sentence-transformers/all-MiniLM-L6-v2', model_kwargs=None, custom_class=None), 'vector_database': VectorDBConfig(type=<VectorDatabase.FAISS: 'faiss'>, collection_name=None, persist_directory=None, client_settings=None, metadata=None, custom_class=None), 'top_k': 5, 'sampling_rate': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2024-10-23 11:43:50,496] Trial 2 finished with value: -0.040341035623224185 and parameters: {'chunking_strategy': <ChunkingStrategy.CHARACTER: 'CharacterTextSplitter'>, 'chunk_size': 500}. Best is trial 0 with value: -0.0033819396699064064.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ashwinaravind/.pyenv/versions/3.12.5/lib/python3.12/site-packages/langchain_core/vectorstores/base.py:784: UserWarning: Relevance scores must be between 0 and 1, got [(Document(metadata={'source': 'sample_data.txt'}, page_content='and indexer components. The goal is to ensure that our pipeline works end-to-end with a simple configuration.'), 0.019551265788898653), (Document(metadata={'source': 'sample_data.txt'}, page_content=\"# sample_data.txt This is a sample document for testing the RAGBuilder data ingestion pipeline. It contains multiple sentences to demonstrate chunking. We'll use this to test our parser, chunker, embedder, and indexer components. The goal is to ensure that our pipeline works end-to-end with a simple\"), -0.03137780583990746)]\n",
      "  warnings.warn(\n",
      "/Users/ashwinaravind/.pyenv/versions/3.12.5/lib/python3.12/site-packages/langchain_core/vectorstores/base.py:784: UserWarning: Relevance scores must be between 0 and 1, got [(Document(metadata={'source': 'sample_data.txt'}, page_content=\"# sample_data.txt This is a sample document for testing the RAGBuilder data ingestion pipeline. It contains multiple sentences to demonstrate chunking. We'll use this to test our parser, chunker, embedder, and indexer components. The goal is to ensure that our pipeline works end-to-end with a simple\"), -0.02304191784772569), (Document(metadata={'source': 'sample_data.txt'}, page_content='and indexer components. The goal is to ensure that our pipeline works end-to-end with a simple configuration.'), -0.19856010824782722)]\n",
      "  warnings.warn(\n",
      "/Users/ashwinaravind/.pyenv/versions/3.12.5/lib/python3.12/site-packages/langchain_core/vectorstores/base.py:784: UserWarning: Relevance scores must be between 0 and 1, got [(Document(metadata={'source': 'sample_data.txt'}, page_content='and indexer components. The goal is to ensure that our pipeline works end-to-end with a simple configuration.'), 0.0550302299842782), (Document(metadata={'source': 'sample_data.txt'}, page_content=\"# sample_data.txt This is a sample document for testing the RAGBuilder data ingestion pipeline. It contains multiple sentences to demonstrate chunking. We'll use this to test our parser, chunker, embedder, and indexer components. The goal is to ensure that our pipeline works end-to-end with a simple\"), -0.08268392317549189)]\n",
      "  warnings.warn(\n",
      "2024-10-23 11:43:54,348 - INFO - Starting trial 5/10\n",
      "2024-10-23 11:43:54,349 - INFO - Trial parameters: {'input_source': 'sample_data.txt', 'test_dataset': 'sample_questions.txt', 'chunking_strategy': <ChunkingStrategy.CHARACTER: 'CharacterTextSplitter'>, 'chunk_overlap': 100, 'chunk_size': 300, 'embedding_model': EmbeddingConfig(type=<EmbeddingModel.HUGGINGFACE: 'huggingface'>, model='sentence-transformers/all-MiniLM-L6-v2', model_kwargs=None, custom_class=None), 'vector_database': VectorDBConfig(type=<VectorDatabase.FAISS: 'faiss'>, collection_name=None, persist_directory=None, client_settings=None, metadata=None, custom_class=None), 'top_k': 5, 'sampling_rate': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2024-10-23 11:43:54,347] Trial 3 finished with value: -0.043513709889629236 and parameters: {'chunking_strategy': <ChunkingStrategy.RECURSIVE: 'RecursiveCharacterTextSplitter'>, 'chunk_size': 300}. Best is trial 0 with value: -0.0033819396699064064.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 11:43:57,260 - INFO - Starting trial 6/10\n",
      "2024-10-23 11:43:57,260 - INFO - Trial parameters: {'input_source': 'sample_data.txt', 'test_dataset': 'sample_questions.txt', 'chunking_strategy': <ChunkingStrategy.CHARACTER: 'CharacterTextSplitter'>, 'chunk_overlap': 100, 'chunk_size': 400, 'embedding_model': EmbeddingConfig(type=<EmbeddingModel.HUGGINGFACE: 'huggingface'>, model='sentence-transformers/all-MiniLM-L6-v2', model_kwargs=None, custom_class=None), 'vector_database': VectorDBConfig(type=<VectorDatabase.FAISS: 'faiss'>, collection_name=None, persist_directory=None, client_settings=None, metadata=None, custom_class=None), 'top_k': 5, 'sampling_rate': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2024-10-23 11:43:57,259] Trial 4 finished with value: -0.040341035623224185 and parameters: {'chunking_strategy': <ChunkingStrategy.CHARACTER: 'CharacterTextSplitter'>, 'chunk_size': 300}. Best is trial 0 with value: -0.0033819396699064064.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 11:44:00,233 - INFO - Starting trial 7/10\n",
      "2024-10-23 11:44:00,234 - INFO - Trial parameters: {'input_source': 'sample_data.txt', 'test_dataset': 'sample_questions.txt', 'chunking_strategy': <ChunkingStrategy.CHARACTER: 'CharacterTextSplitter'>, 'chunk_overlap': 100, 'chunk_size': 400, 'embedding_model': EmbeddingConfig(type=<EmbeddingModel.HUGGINGFACE: 'huggingface'>, model='sentence-transformers/all-MiniLM-L6-v2', model_kwargs=None, custom_class=None), 'vector_database': VectorDBConfig(type=<VectorDatabase.FAISS: 'faiss'>, collection_name=None, persist_directory=None, client_settings=None, metadata=None, custom_class=None), 'top_k': 5, 'sampling_rate': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2024-10-23 11:44:00,232] Trial 5 finished with value: -0.040341035623224185 and parameters: {'chunking_strategy': <ChunkingStrategy.CHARACTER: 'CharacterTextSplitter'>, 'chunk_size': 400}. Best is trial 0 with value: -0.0033819396699064064.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 11:44:03,474 - INFO - Starting trial 8/10\n",
      "2024-10-23 11:44:03,475 - INFO - Trial parameters: {'input_source': 'sample_data.txt', 'test_dataset': 'sample_questions.txt', 'chunking_strategy': <ChunkingStrategy.RECURSIVE: 'RecursiveCharacterTextSplitter'>, 'chunk_overlap': 100, 'chunk_size': 400, 'embedding_model': EmbeddingConfig(type=<EmbeddingModel.HUGGINGFACE: 'huggingface'>, model='sentence-transformers/all-MiniLM-L6-v2', model_kwargs=None, custom_class=None), 'vector_database': VectorDBConfig(type=<VectorDatabase.FAISS: 'faiss'>, collection_name=None, persist_directory=None, client_settings=None, metadata=None, custom_class=None), 'top_k': 5, 'sampling_rate': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2024-10-23 11:44:03,473] Trial 6 finished with value: -0.040341035623224185 and parameters: {'chunking_strategy': <ChunkingStrategy.CHARACTER: 'CharacterTextSplitter'>, 'chunk_size': 400}. Best is trial 0 with value: -0.0033819396699064064.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 11:44:06,452 - INFO - Starting trial 9/10\n",
      "2024-10-23 11:44:06,453 - INFO - Trial parameters: {'input_source': 'sample_data.txt', 'test_dataset': 'sample_questions.txt', 'chunking_strategy': <ChunkingStrategy.CHARACTER: 'CharacterTextSplitter'>, 'chunk_overlap': 100, 'chunk_size': 300, 'embedding_model': EmbeddingConfig(type=<EmbeddingModel.HUGGINGFACE: 'huggingface'>, model='sentence-transformers/all-MiniLM-L6-v2', model_kwargs=None, custom_class=None), 'vector_database': VectorDBConfig(type=<VectorDatabase.FAISS: 'faiss'>, collection_name=None, persist_directory=None, client_settings=None, metadata=None, custom_class=None), 'top_k': 5, 'sampling_rate': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2024-10-23 11:44:06,451] Trial 7 finished with value: -0.040341035623224185 and parameters: {'chunking_strategy': <ChunkingStrategy.RECURSIVE: 'RecursiveCharacterTextSplitter'>, 'chunk_size': 400}. Best is trial 0 with value: -0.0033819396699064064.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 11:44:09,467 - INFO - Starting trial 10/10\n",
      "2024-10-23 11:44:09,467 - INFO - Trial parameters: {'input_source': 'sample_data.txt', 'test_dataset': 'sample_questions.txt', 'chunking_strategy': <ChunkingStrategy.RECURSIVE: 'RecursiveCharacterTextSplitter'>, 'chunk_overlap': 100, 'chunk_size': 100, 'embedding_model': EmbeddingConfig(type=<EmbeddingModel.HUGGINGFACE: 'huggingface'>, model='sentence-transformers/all-MiniLM-L6-v2', model_kwargs=None, custom_class=None), 'vector_database': VectorDBConfig(type=<VectorDatabase.FAISS: 'faiss'>, collection_name=None, persist_directory=None, client_settings=None, metadata=None, custom_class=None), 'top_k': 5, 'sampling_rate': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2024-10-23 11:44:09,466] Trial 8 finished with value: -0.040341035623224185 and parameters: {'chunking_strategy': <ChunkingStrategy.CHARACTER: 'CharacterTextSplitter'>, 'chunk_size': 300}. Best is trial 0 with value: -0.0033819396699064064.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ashwinaravind/.pyenv/versions/3.12.5/lib/python3.12/site-packages/langchain_core/vectorstores/base.py:784: UserWarning: Relevance scores must be between 0 and 1, got [(Document(metadata={'source': 'sample_data.txt'}, page_content=\"It contains multiple sentences to demonstrate chunking. We'll use this to test our parser, chunker,\"), 0.12239126202942052), (Document(metadata={'source': 'sample_data.txt'}, page_content=\"to demonstrate chunking. We'll use this to test our parser, chunker, embedder, and indexer\"), 0.1007307321742168), (Document(metadata={'source': 'sample_data.txt'}, page_content='components. The goal is to ensure that our pipeline works end-to-end with a simple configuration.'), 0.04040797094930271), (Document(metadata={'source': 'sample_data.txt'}, page_content='document for testing the RAGBuilder data ingestion pipeline. It contains multiple sentences to'), -0.008342530079975319), (Document(metadata={'source': 'sample_data.txt'}, page_content=\"pipeline. It contains multiple sentences to demonstrate chunking. We'll use this to test our\"), -0.01123591123024803)]\n",
      "  warnings.warn(\n",
      "2024-10-23 11:44:13,634 - INFO - Optimization completed. Best score: 0.1051\n",
      "2024-10-23 11:44:13,634 - INFO - Best parameters: {'chunking_strategy': <ChunkingStrategy.RECURSIVE: 'RecursiveCharacterTextSplitter'>, 'chunk_size': 100}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2024-10-23 11:44:13,632] Trial 9 finished with value: 0.10513259398933295 and parameters: {'chunking_strategy': <ChunkingStrategy.RECURSIVE: 'RecursiveCharacterTextSplitter'>, 'chunk_size': 100}. Best is trial 9 with value: 0.10513259398933295.\n"
     ]
    }
   ],
   "source": [
    "best_config, best_score, best_indexer = run_retriever_from_dict(sample_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(metadata={'source': 'sample_data.txt'}, page_content=\"It contains multiple sentences to demonstrate chunking. We'll use this to test our parser, chunker,\"),\n",
       "  0.12169288874959505),\n",
       " (Document(metadata={'source': 'sample_data.txt'}, page_content=\"to demonstrate chunking. We'll use this to test our parser, chunker, embedder, and indexer\"),\n",
       "  0.11005108625391591),\n",
       " (Document(metadata={'source': 'sample_data.txt'}, page_content='components. The goal is to ensure that our pipeline works end-to-end with a simple configuration.'),\n",
       "  0.04864043057523859),\n",
       " (Document(metadata={'source': 'sample_data.txt'}, page_content='document for testing the RAGBuilder data ingestion pipeline. It contains multiple sentences to'),\n",
       "  0.007918819893588891)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_indexer.similarity_search_with_relevance_scores(\"What is the purpose of this document\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk_overlap: 100\n",
      "chunk_size: 100\n",
      "chunking_strategy: RecursiveCharacterTextSplitter\n",
      "custom_chunker: null\n",
      "document_loader:\n",
      "  custom_class: null\n",
      "  loader_kwargs: null\n",
      "  type: !!python/object/apply:ragbuilder.data_ingest.config.ParserType\n",
      "  - unstructured\n",
      "embedding_model:\n",
      "  custom_class: null\n",
      "  model: sentence-transformers/all-MiniLM-L6-v2\n",
      "  model_kwargs: null\n",
      "  type: !!python/object/apply:ragbuilder.data_ingest.config.EmbeddingModel\n",
      "  - huggingface\n",
      "input_source: sample_data.txt\n",
      "sampling_rate: null\n",
      "test_dataset: sample_questions.txt\n",
      "top_k: 5\n",
      "vector_database:\n",
      "  client_settings: null\n",
      "  collection_name: null\n",
      "  custom_class: null\n",
      "  metadata: null\n",
      "  persist_directory: null\n",
      "  type: !!python/object/apply:ragbuilder.data_ingest.config.VectorDatabase\n",
      "  - faiss\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(yaml.dump(best_config.model_dump()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ragbuilder",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
