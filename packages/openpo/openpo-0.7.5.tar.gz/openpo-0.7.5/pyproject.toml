[tool.poetry]
name = "openpo"
version = "0.7.5"
description = "Build high quality synthetic datasets with AI feedback from 200+ LLMs"
authors = ["Daniel Lee <dannylee1020@gmail.com>"]
license = "Apache-2.0"
keywords = ["llm", "finetuning", "ai", "rlaif", "preference tuning", "synthetic data generation", "synthetic data"]
include = ["LICENSE", "README.md"]
repository = "https://github.com/dannylee1020/openpo"
documentation="https://docs.openpo.dev"
readme = "README.md"

[tool.poetry.dependencies]
python = ">=3.10.1,<4.0"
pydantic = "^2.9.2"
boto3 = "^1.35.57"
numpy = "^1.26.4"
huggingface-hub = "^0.26.2"
httpx = "^0.27.2"
datasets = "^3.1.0"
pandas = "^2.2.3"
openai = "^1.57.1"
anthropic = "^0.40.0"

llm-blender = {version = "^0.0.2", optional = true}
prometheus-eval = {version = "^0.1.20", optional = true}
vllm = {version = "^0.6.4.post1", optional = true}
triton = {version = '3.1.0', optional = true}


[tool.poetry.group.docs.dependencies]
mkdocs-material = "^9.5.44"
mkdocstrings-python = "^1.12.2"

[tool.poetry.extras]
eval= ["llm-blender", "prometheus-eval", "vllm", "triton"]
vllm = ["vllm", "triton"]

[build-system]
requires = ["poetry-core"]
build-backend = "poetry.core.masonry.api"

