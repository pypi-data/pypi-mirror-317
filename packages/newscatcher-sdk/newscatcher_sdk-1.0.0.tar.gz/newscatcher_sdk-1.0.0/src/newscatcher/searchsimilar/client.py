# This file was auto-generated by Fern from our API Definition.

import typing
from ..core.client_wrapper import SyncClientWrapper
from ..core.request_options import RequestOptions
from .types.search_similar_get_response import SearchSimilarGetResponse
from ..core.pydantic_utilities import parse_obj_as
from ..errors.unprocessable_entity_error import UnprocessableEntityError
from ..types.http_validation_error import HttpValidationError
from json.decoder import JSONDecodeError
from ..core.api_error import ApiError
from .types.more_like_this_request_from import MoreLikeThisRequestFrom
from .types.more_like_this_request_to import MoreLikeThisRequestTo
from .types.more_like_this_request_ranked_only import MoreLikeThisRequestRankedOnly
from .types.search_similar_post_response import SearchSimilarPostResponse
from ..core.serialization import convert_and_respect_annotation_metadata
from ..core.client_wrapper import AsyncClientWrapper

# this is used as the default value for optional parameters
OMIT = typing.cast(typing.Any, ...)


class SearchsimilarClient:
    def __init__(self, *, client_wrapper: SyncClientWrapper):
        self._client_wrapper = client_wrapper

    def get(
        self,
        *,
        q: str,
        predefined_sources: str,
        sources: str,
        not_sources: str,
        lang: str,
        not_lang: str,
        countries: str,
        not_countries: str,
        parent_url: str,
        all_links: str,
        all_domain_links: str,
        iptc_tags: str,
        not_iptc_tags: str,
        search_in: typing.Optional[str] = None,
        include_similar_documents: typing.Optional[bool] = None,
        similar_documents_number: typing.Optional[int] = None,
        similar_documents_fields: typing.Optional[str] = None,
        from_: typing.Optional[str] = None,
        to: typing.Optional[str] = None,
        by_parse_date: typing.Optional[bool] = None,
        published_date_precision: typing.Optional[str] = None,
        sort_by: typing.Optional[str] = None,
        ranked_only: typing.Optional[str] = None,
        from_rank: typing.Optional[int] = None,
        to_rank: typing.Optional[int] = None,
        is_headline: typing.Optional[bool] = None,
        is_opinion: typing.Optional[bool] = None,
        is_paid_content: typing.Optional[bool] = None,
        word_count_min: typing.Optional[int] = None,
        word_count_max: typing.Optional[int] = None,
        page: typing.Optional[int] = None,
        page_size: typing.Optional[int] = None,
        include_nlp_data: typing.Optional[bool] = None,
        has_nlp: typing.Optional[bool] = None,
        theme: typing.Optional[str] = None,
        not_theme: typing.Optional[str] = None,
        title_sentiment_min: typing.Optional[float] = None,
        title_sentiment_max: typing.Optional[float] = None,
        content_sentiment_min: typing.Optional[float] = None,
        content_sentiment_max: typing.Optional[float] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> SearchSimilarGetResponse:
        """
        This endpoint returns a list of articles that are similar to the query provided. You also have the option to get similar articles for the results of a search.

        Parameters
        ----------
        q : str

        predefined_sources : str

        sources : str

        not_sources : str

        lang : str

        not_lang : str

        countries : str

        not_countries : str

        parent_url : str

        all_links : str

        all_domain_links : str

        iptc_tags : str

        not_iptc_tags : str

        search_in : typing.Optional[str]

        include_similar_documents : typing.Optional[bool]

        similar_documents_number : typing.Optional[int]

        similar_documents_fields : typing.Optional[str]

        from_ : typing.Optional[str]

        to : typing.Optional[str]

        by_parse_date : typing.Optional[bool]

        published_date_precision : typing.Optional[str]

        sort_by : typing.Optional[str]

        ranked_only : typing.Optional[str]

        from_rank : typing.Optional[int]

        to_rank : typing.Optional[int]

        is_headline : typing.Optional[bool]

        is_opinion : typing.Optional[bool]

        is_paid_content : typing.Optional[bool]

        word_count_min : typing.Optional[int]

        word_count_max : typing.Optional[int]

        page : typing.Optional[int]

        page_size : typing.Optional[int]

        include_nlp_data : typing.Optional[bool]

        has_nlp : typing.Optional[bool]

        theme : typing.Optional[str]

        not_theme : typing.Optional[str]

        title_sentiment_min : typing.Optional[float]

        title_sentiment_max : typing.Optional[float]

        content_sentiment_min : typing.Optional[float]

        content_sentiment_max : typing.Optional[float]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        SearchSimilarGetResponse
            Successful Response

        Examples
        --------
        from newscatcher import NewscatcherApi

        client = NewscatcherApi(
            api_token="YOUR_API_TOKEN",
        )
        client.searchsimilar.get(
            q="q",
            predefined_sources="predefined_sources",
            sources="sources",
            not_sources="not_sources",
            lang="lang",
            not_lang="not_lang",
            countries="countries",
            not_countries="not_countries",
            parent_url="parent_url",
            all_links="all_links",
            all_domain_links="all_domain_links",
            iptc_tags="iptc_tags",
            not_iptc_tags="not_iptc_tags",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            "api/search_similar",
            method="GET",
            params={
                "q": q,
                "search_in": search_in,
                "include_similar_documents": include_similar_documents,
                "similar_documents_number": similar_documents_number,
                "similar_documents_fields": similar_documents_fields,
                "predefined_sources": predefined_sources,
                "sources": sources,
                "not_sources": not_sources,
                "lang": lang,
                "not_lang": not_lang,
                "countries": countries,
                "not_countries": not_countries,
                "from_": from_,
                "to_": to,
                "by_parse_date": by_parse_date,
                "published_date_precision": published_date_precision,
                "sort_by": sort_by,
                "ranked_only": ranked_only,
                "from_rank": from_rank,
                "to_rank": to_rank,
                "is_headline": is_headline,
                "is_opinion": is_opinion,
                "is_paid_content": is_paid_content,
                "parent_url": parent_url,
                "all_links": all_links,
                "all_domain_links": all_domain_links,
                "word_count_min": word_count_min,
                "word_count_max": word_count_max,
                "page": page,
                "page_size": page_size,
                "include_nlp_data": include_nlp_data,
                "has_nlp": has_nlp,
                "theme": theme,
                "not_theme": not_theme,
                "title_sentiment_min": title_sentiment_min,
                "title_sentiment_max": title_sentiment_max,
                "content_sentiment_min": content_sentiment_min,
                "content_sentiment_max": content_sentiment_max,
                "iptc_tags": iptc_tags,
                "not_iptc_tags": not_iptc_tags,
            },
            request_options=request_options,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    SearchSimilarGetResponse,
                    parse_obj_as(
                        type_=SearchSimilarGetResponse,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    typing.cast(
                        HttpValidationError,
                        parse_obj_as(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def post(
        self,
        *,
        q: str,
        search_in: typing.Optional[str] = OMIT,
        include_similar_documents: typing.Optional[bool] = OMIT,
        similar_documents_number: typing.Optional[int] = OMIT,
        similar_documents_fields: typing.Optional[str] = OMIT,
        predefined_sources: typing.Optional[typing.Optional[typing.Any]] = OMIT,
        sources: typing.Optional[typing.Optional[typing.Any]] = OMIT,
        not_sources: typing.Optional[typing.Optional[typing.Any]] = OMIT,
        lang: typing.Optional[typing.Optional[typing.Any]] = OMIT,
        not_lang: typing.Optional[typing.Optional[typing.Any]] = OMIT,
        countries: typing.Optional[typing.Optional[typing.Any]] = OMIT,
        not_countries: typing.Optional[typing.Optional[typing.Any]] = OMIT,
        from_: typing.Optional[MoreLikeThisRequestFrom] = OMIT,
        to: typing.Optional[MoreLikeThisRequestTo] = OMIT,
        by_parse_date: typing.Optional[bool] = OMIT,
        published_date_precision: typing.Optional[str] = OMIT,
        sort_by: typing.Optional[str] = OMIT,
        ranked_only: typing.Optional[MoreLikeThisRequestRankedOnly] = OMIT,
        from_rank: typing.Optional[int] = OMIT,
        to_rank: typing.Optional[int] = OMIT,
        is_headline: typing.Optional[bool] = OMIT,
        is_opinion: typing.Optional[bool] = OMIT,
        is_paid_content: typing.Optional[bool] = OMIT,
        parent_url: typing.Optional[typing.Optional[typing.Any]] = OMIT,
        all_links: typing.Optional[typing.Optional[typing.Any]] = OMIT,
        all_domain_links: typing.Optional[typing.Optional[typing.Any]] = OMIT,
        word_count_min: typing.Optional[int] = OMIT,
        word_count_max: typing.Optional[int] = OMIT,
        page: typing.Optional[int] = OMIT,
        page_size: typing.Optional[int] = OMIT,
        include_nlp_data: typing.Optional[bool] = OMIT,
        has_nlp: typing.Optional[bool] = OMIT,
        theme: typing.Optional[str] = OMIT,
        not_theme: typing.Optional[str] = OMIT,
        title_sentiment_min: typing.Optional[float] = OMIT,
        title_sentiment_max: typing.Optional[float] = OMIT,
        content_sentiment_min: typing.Optional[float] = OMIT,
        content_sentiment_max: typing.Optional[float] = OMIT,
        iptc_tags: typing.Optional[typing.Optional[typing.Any]] = OMIT,
        not_iptc_tags: typing.Optional[typing.Optional[typing.Any]] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> SearchSimilarPostResponse:
        """
        This endpoint returns a list of articles that are similar to the query provided. You also have the option to get similar articles for the results of a search.

        Parameters
        ----------
        q : str

        search_in : typing.Optional[str]

        include_similar_documents : typing.Optional[bool]

        similar_documents_number : typing.Optional[int]

        similar_documents_fields : typing.Optional[str]

        predefined_sources : typing.Optional[typing.Optional[typing.Any]]

        sources : typing.Optional[typing.Optional[typing.Any]]

        not_sources : typing.Optional[typing.Optional[typing.Any]]

        lang : typing.Optional[typing.Optional[typing.Any]]

        not_lang : typing.Optional[typing.Optional[typing.Any]]

        countries : typing.Optional[typing.Optional[typing.Any]]

        not_countries : typing.Optional[typing.Optional[typing.Any]]

        from_ : typing.Optional[MoreLikeThisRequestFrom]

        to : typing.Optional[MoreLikeThisRequestTo]

        by_parse_date : typing.Optional[bool]

        published_date_precision : typing.Optional[str]

        sort_by : typing.Optional[str]

        ranked_only : typing.Optional[MoreLikeThisRequestRankedOnly]

        from_rank : typing.Optional[int]

        to_rank : typing.Optional[int]

        is_headline : typing.Optional[bool]

        is_opinion : typing.Optional[bool]

        is_paid_content : typing.Optional[bool]

        parent_url : typing.Optional[typing.Optional[typing.Any]]

        all_links : typing.Optional[typing.Optional[typing.Any]]

        all_domain_links : typing.Optional[typing.Optional[typing.Any]]

        word_count_min : typing.Optional[int]

        word_count_max : typing.Optional[int]

        page : typing.Optional[int]

        page_size : typing.Optional[int]

        include_nlp_data : typing.Optional[bool]

        has_nlp : typing.Optional[bool]

        theme : typing.Optional[str]

        not_theme : typing.Optional[str]

        title_sentiment_min : typing.Optional[float]

        title_sentiment_max : typing.Optional[float]

        content_sentiment_min : typing.Optional[float]

        content_sentiment_max : typing.Optional[float]

        iptc_tags : typing.Optional[typing.Optional[typing.Any]]

        not_iptc_tags : typing.Optional[typing.Optional[typing.Any]]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        SearchSimilarPostResponse
            Successful Response

        Examples
        --------
        from newscatcher import NewscatcherApi

        client = NewscatcherApi(
            api_token="YOUR_API_TOKEN",
        )
        client.searchsimilar.post(
            q="q",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            "api/search_similar",
            method="POST",
            json={
                "q": q,
                "search_in": search_in,
                "include_similar_documents": include_similar_documents,
                "similar_documents_number": similar_documents_number,
                "similar_documents_fields": similar_documents_fields,
                "predefined_sources": predefined_sources,
                "sources": sources,
                "not_sources": not_sources,
                "lang": lang,
                "not_lang": not_lang,
                "countries": countries,
                "not_countries": not_countries,
                "from_": convert_and_respect_annotation_metadata(
                    object_=from_, annotation=MoreLikeThisRequestFrom, direction="write"
                ),
                "to_": convert_and_respect_annotation_metadata(
                    object_=to, annotation=MoreLikeThisRequestTo, direction="write"
                ),
                "by_parse_date": by_parse_date,
                "published_date_precision": published_date_precision,
                "sort_by": sort_by,
                "ranked_only": convert_and_respect_annotation_metadata(
                    object_=ranked_only, annotation=MoreLikeThisRequestRankedOnly, direction="write"
                ),
                "from_rank": from_rank,
                "to_rank": to_rank,
                "is_headline": is_headline,
                "is_opinion": is_opinion,
                "is_paid_content": is_paid_content,
                "parent_url": parent_url,
                "all_links": all_links,
                "all_domain_links": all_domain_links,
                "word_count_min": word_count_min,
                "word_count_max": word_count_max,
                "page": page,
                "page_size": page_size,
                "include_nlp_data": include_nlp_data,
                "has_nlp": has_nlp,
                "theme": theme,
                "not_theme": not_theme,
                "title_sentiment_min": title_sentiment_min,
                "title_sentiment_max": title_sentiment_max,
                "content_sentiment_min": content_sentiment_min,
                "content_sentiment_max": content_sentiment_max,
                "iptc_tags": iptc_tags,
                "not_iptc_tags": not_iptc_tags,
            },
            headers={
                "content-type": "application/json",
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    SearchSimilarPostResponse,
                    parse_obj_as(
                        type_=SearchSimilarPostResponse,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    typing.cast(
                        HttpValidationError,
                        parse_obj_as(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)


class AsyncSearchsimilarClient:
    def __init__(self, *, client_wrapper: AsyncClientWrapper):
        self._client_wrapper = client_wrapper

    async def get(
        self,
        *,
        q: str,
        predefined_sources: str,
        sources: str,
        not_sources: str,
        lang: str,
        not_lang: str,
        countries: str,
        not_countries: str,
        parent_url: str,
        all_links: str,
        all_domain_links: str,
        iptc_tags: str,
        not_iptc_tags: str,
        search_in: typing.Optional[str] = None,
        include_similar_documents: typing.Optional[bool] = None,
        similar_documents_number: typing.Optional[int] = None,
        similar_documents_fields: typing.Optional[str] = None,
        from_: typing.Optional[str] = None,
        to: typing.Optional[str] = None,
        by_parse_date: typing.Optional[bool] = None,
        published_date_precision: typing.Optional[str] = None,
        sort_by: typing.Optional[str] = None,
        ranked_only: typing.Optional[str] = None,
        from_rank: typing.Optional[int] = None,
        to_rank: typing.Optional[int] = None,
        is_headline: typing.Optional[bool] = None,
        is_opinion: typing.Optional[bool] = None,
        is_paid_content: typing.Optional[bool] = None,
        word_count_min: typing.Optional[int] = None,
        word_count_max: typing.Optional[int] = None,
        page: typing.Optional[int] = None,
        page_size: typing.Optional[int] = None,
        include_nlp_data: typing.Optional[bool] = None,
        has_nlp: typing.Optional[bool] = None,
        theme: typing.Optional[str] = None,
        not_theme: typing.Optional[str] = None,
        title_sentiment_min: typing.Optional[float] = None,
        title_sentiment_max: typing.Optional[float] = None,
        content_sentiment_min: typing.Optional[float] = None,
        content_sentiment_max: typing.Optional[float] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> SearchSimilarGetResponse:
        """
        This endpoint returns a list of articles that are similar to the query provided. You also have the option to get similar articles for the results of a search.

        Parameters
        ----------
        q : str

        predefined_sources : str

        sources : str

        not_sources : str

        lang : str

        not_lang : str

        countries : str

        not_countries : str

        parent_url : str

        all_links : str

        all_domain_links : str

        iptc_tags : str

        not_iptc_tags : str

        search_in : typing.Optional[str]

        include_similar_documents : typing.Optional[bool]

        similar_documents_number : typing.Optional[int]

        similar_documents_fields : typing.Optional[str]

        from_ : typing.Optional[str]

        to : typing.Optional[str]

        by_parse_date : typing.Optional[bool]

        published_date_precision : typing.Optional[str]

        sort_by : typing.Optional[str]

        ranked_only : typing.Optional[str]

        from_rank : typing.Optional[int]

        to_rank : typing.Optional[int]

        is_headline : typing.Optional[bool]

        is_opinion : typing.Optional[bool]

        is_paid_content : typing.Optional[bool]

        word_count_min : typing.Optional[int]

        word_count_max : typing.Optional[int]

        page : typing.Optional[int]

        page_size : typing.Optional[int]

        include_nlp_data : typing.Optional[bool]

        has_nlp : typing.Optional[bool]

        theme : typing.Optional[str]

        not_theme : typing.Optional[str]

        title_sentiment_min : typing.Optional[float]

        title_sentiment_max : typing.Optional[float]

        content_sentiment_min : typing.Optional[float]

        content_sentiment_max : typing.Optional[float]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        SearchSimilarGetResponse
            Successful Response

        Examples
        --------
        import asyncio

        from newscatcher import AsyncNewscatcherApi

        client = AsyncNewscatcherApi(
            api_token="YOUR_API_TOKEN",
        )


        async def main() -> None:
            await client.searchsimilar.get(
                q="q",
                predefined_sources="predefined_sources",
                sources="sources",
                not_sources="not_sources",
                lang="lang",
                not_lang="not_lang",
                countries="countries",
                not_countries="not_countries",
                parent_url="parent_url",
                all_links="all_links",
                all_domain_links="all_domain_links",
                iptc_tags="iptc_tags",
                not_iptc_tags="not_iptc_tags",
            )


        asyncio.run(main())
        """
        _response = await self._client_wrapper.httpx_client.request(
            "api/search_similar",
            method="GET",
            params={
                "q": q,
                "search_in": search_in,
                "include_similar_documents": include_similar_documents,
                "similar_documents_number": similar_documents_number,
                "similar_documents_fields": similar_documents_fields,
                "predefined_sources": predefined_sources,
                "sources": sources,
                "not_sources": not_sources,
                "lang": lang,
                "not_lang": not_lang,
                "countries": countries,
                "not_countries": not_countries,
                "from_": from_,
                "to_": to,
                "by_parse_date": by_parse_date,
                "published_date_precision": published_date_precision,
                "sort_by": sort_by,
                "ranked_only": ranked_only,
                "from_rank": from_rank,
                "to_rank": to_rank,
                "is_headline": is_headline,
                "is_opinion": is_opinion,
                "is_paid_content": is_paid_content,
                "parent_url": parent_url,
                "all_links": all_links,
                "all_domain_links": all_domain_links,
                "word_count_min": word_count_min,
                "word_count_max": word_count_max,
                "page": page,
                "page_size": page_size,
                "include_nlp_data": include_nlp_data,
                "has_nlp": has_nlp,
                "theme": theme,
                "not_theme": not_theme,
                "title_sentiment_min": title_sentiment_min,
                "title_sentiment_max": title_sentiment_max,
                "content_sentiment_min": content_sentiment_min,
                "content_sentiment_max": content_sentiment_max,
                "iptc_tags": iptc_tags,
                "not_iptc_tags": not_iptc_tags,
            },
            request_options=request_options,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    SearchSimilarGetResponse,
                    parse_obj_as(
                        type_=SearchSimilarGetResponse,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    typing.cast(
                        HttpValidationError,
                        parse_obj_as(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def post(
        self,
        *,
        q: str,
        search_in: typing.Optional[str] = OMIT,
        include_similar_documents: typing.Optional[bool] = OMIT,
        similar_documents_number: typing.Optional[int] = OMIT,
        similar_documents_fields: typing.Optional[str] = OMIT,
        predefined_sources: typing.Optional[typing.Optional[typing.Any]] = OMIT,
        sources: typing.Optional[typing.Optional[typing.Any]] = OMIT,
        not_sources: typing.Optional[typing.Optional[typing.Any]] = OMIT,
        lang: typing.Optional[typing.Optional[typing.Any]] = OMIT,
        not_lang: typing.Optional[typing.Optional[typing.Any]] = OMIT,
        countries: typing.Optional[typing.Optional[typing.Any]] = OMIT,
        not_countries: typing.Optional[typing.Optional[typing.Any]] = OMIT,
        from_: typing.Optional[MoreLikeThisRequestFrom] = OMIT,
        to: typing.Optional[MoreLikeThisRequestTo] = OMIT,
        by_parse_date: typing.Optional[bool] = OMIT,
        published_date_precision: typing.Optional[str] = OMIT,
        sort_by: typing.Optional[str] = OMIT,
        ranked_only: typing.Optional[MoreLikeThisRequestRankedOnly] = OMIT,
        from_rank: typing.Optional[int] = OMIT,
        to_rank: typing.Optional[int] = OMIT,
        is_headline: typing.Optional[bool] = OMIT,
        is_opinion: typing.Optional[bool] = OMIT,
        is_paid_content: typing.Optional[bool] = OMIT,
        parent_url: typing.Optional[typing.Optional[typing.Any]] = OMIT,
        all_links: typing.Optional[typing.Optional[typing.Any]] = OMIT,
        all_domain_links: typing.Optional[typing.Optional[typing.Any]] = OMIT,
        word_count_min: typing.Optional[int] = OMIT,
        word_count_max: typing.Optional[int] = OMIT,
        page: typing.Optional[int] = OMIT,
        page_size: typing.Optional[int] = OMIT,
        include_nlp_data: typing.Optional[bool] = OMIT,
        has_nlp: typing.Optional[bool] = OMIT,
        theme: typing.Optional[str] = OMIT,
        not_theme: typing.Optional[str] = OMIT,
        title_sentiment_min: typing.Optional[float] = OMIT,
        title_sentiment_max: typing.Optional[float] = OMIT,
        content_sentiment_min: typing.Optional[float] = OMIT,
        content_sentiment_max: typing.Optional[float] = OMIT,
        iptc_tags: typing.Optional[typing.Optional[typing.Any]] = OMIT,
        not_iptc_tags: typing.Optional[typing.Optional[typing.Any]] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> SearchSimilarPostResponse:
        """
        This endpoint returns a list of articles that are similar to the query provided. You also have the option to get similar articles for the results of a search.

        Parameters
        ----------
        q : str

        search_in : typing.Optional[str]

        include_similar_documents : typing.Optional[bool]

        similar_documents_number : typing.Optional[int]

        similar_documents_fields : typing.Optional[str]

        predefined_sources : typing.Optional[typing.Optional[typing.Any]]

        sources : typing.Optional[typing.Optional[typing.Any]]

        not_sources : typing.Optional[typing.Optional[typing.Any]]

        lang : typing.Optional[typing.Optional[typing.Any]]

        not_lang : typing.Optional[typing.Optional[typing.Any]]

        countries : typing.Optional[typing.Optional[typing.Any]]

        not_countries : typing.Optional[typing.Optional[typing.Any]]

        from_ : typing.Optional[MoreLikeThisRequestFrom]

        to : typing.Optional[MoreLikeThisRequestTo]

        by_parse_date : typing.Optional[bool]

        published_date_precision : typing.Optional[str]

        sort_by : typing.Optional[str]

        ranked_only : typing.Optional[MoreLikeThisRequestRankedOnly]

        from_rank : typing.Optional[int]

        to_rank : typing.Optional[int]

        is_headline : typing.Optional[bool]

        is_opinion : typing.Optional[bool]

        is_paid_content : typing.Optional[bool]

        parent_url : typing.Optional[typing.Optional[typing.Any]]

        all_links : typing.Optional[typing.Optional[typing.Any]]

        all_domain_links : typing.Optional[typing.Optional[typing.Any]]

        word_count_min : typing.Optional[int]

        word_count_max : typing.Optional[int]

        page : typing.Optional[int]

        page_size : typing.Optional[int]

        include_nlp_data : typing.Optional[bool]

        has_nlp : typing.Optional[bool]

        theme : typing.Optional[str]

        not_theme : typing.Optional[str]

        title_sentiment_min : typing.Optional[float]

        title_sentiment_max : typing.Optional[float]

        content_sentiment_min : typing.Optional[float]

        content_sentiment_max : typing.Optional[float]

        iptc_tags : typing.Optional[typing.Optional[typing.Any]]

        not_iptc_tags : typing.Optional[typing.Optional[typing.Any]]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        SearchSimilarPostResponse
            Successful Response

        Examples
        --------
        import asyncio

        from newscatcher import AsyncNewscatcherApi

        client = AsyncNewscatcherApi(
            api_token="YOUR_API_TOKEN",
        )


        async def main() -> None:
            await client.searchsimilar.post(
                q="q",
            )


        asyncio.run(main())
        """
        _response = await self._client_wrapper.httpx_client.request(
            "api/search_similar",
            method="POST",
            json={
                "q": q,
                "search_in": search_in,
                "include_similar_documents": include_similar_documents,
                "similar_documents_number": similar_documents_number,
                "similar_documents_fields": similar_documents_fields,
                "predefined_sources": predefined_sources,
                "sources": sources,
                "not_sources": not_sources,
                "lang": lang,
                "not_lang": not_lang,
                "countries": countries,
                "not_countries": not_countries,
                "from_": convert_and_respect_annotation_metadata(
                    object_=from_, annotation=MoreLikeThisRequestFrom, direction="write"
                ),
                "to_": convert_and_respect_annotation_metadata(
                    object_=to, annotation=MoreLikeThisRequestTo, direction="write"
                ),
                "by_parse_date": by_parse_date,
                "published_date_precision": published_date_precision,
                "sort_by": sort_by,
                "ranked_only": convert_and_respect_annotation_metadata(
                    object_=ranked_only, annotation=MoreLikeThisRequestRankedOnly, direction="write"
                ),
                "from_rank": from_rank,
                "to_rank": to_rank,
                "is_headline": is_headline,
                "is_opinion": is_opinion,
                "is_paid_content": is_paid_content,
                "parent_url": parent_url,
                "all_links": all_links,
                "all_domain_links": all_domain_links,
                "word_count_min": word_count_min,
                "word_count_max": word_count_max,
                "page": page,
                "page_size": page_size,
                "include_nlp_data": include_nlp_data,
                "has_nlp": has_nlp,
                "theme": theme,
                "not_theme": not_theme,
                "title_sentiment_min": title_sentiment_min,
                "title_sentiment_max": title_sentiment_max,
                "content_sentiment_min": content_sentiment_min,
                "content_sentiment_max": content_sentiment_max,
                "iptc_tags": iptc_tags,
                "not_iptc_tags": not_iptc_tags,
            },
            headers={
                "content-type": "application/json",
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    SearchSimilarPostResponse,
                    parse_obj_as(
                        type_=SearchSimilarPostResponse,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    typing.cast(
                        HttpValidationError,
                        parse_obj_as(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)
