# This file was auto-generated by Fern from our API Definition.

import typing
from ..core.client_wrapper import SyncClientWrapper
from ..core.request_options import RequestOptions
from .types.search_get_response import SearchGetResponse
from ..core.pydantic_utilities import parse_obj_as
from ..errors.unprocessable_entity_error import UnprocessableEntityError
from ..types.http_validation_error import HttpValidationError
from json.decoder import JSONDecodeError
from ..core.api_error import ApiError
from .types.search_request_from import SearchRequestFrom
from .types.search_request_to import SearchRequestTo
from .types.search_request_by_parse_date import SearchRequestByParseDate
from .types.search_request_ranked_only import SearchRequestRankedOnly
from .types.search_request_from_rank import SearchRequestFromRank
from .types.search_request_to_rank import SearchRequestToRank
from .types.search_request_is_headline import SearchRequestIsHeadline
from .types.search_request_is_opinion import SearchRequestIsOpinion
from .types.search_request_is_paid_content import SearchRequestIsPaidContent
from .types.search_request_word_count_min import SearchRequestWordCountMin
from .types.search_request_word_count_max import SearchRequestWordCountMax
from .types.search_request_page import SearchRequestPage
from .types.search_request_page_size import SearchRequestPageSize
from .types.search_request_clustering_enabled import SearchRequestClusteringEnabled
from .types.search_request_clustering_threshold import SearchRequestClusteringThreshold
from .types.search_request_include_nlp_data import SearchRequestIncludeNlpData
from .types.search_post_response import SearchPostResponse
from ..core.serialization import convert_and_respect_annotation_metadata
from ..core.client_wrapper import AsyncClientWrapper

# this is used as the default value for optional parameters
OMIT = typing.cast(typing.Any, ...)


class SearchClient:
    def __init__(self, *, client_wrapper: SyncClientWrapper):
        self._client_wrapper = client_wrapper

    def get(
        self,
        *,
        q: str,
        predefined_sources: str,
        sources: str,
        not_sources: str,
        lang: str,
        not_lang: str,
        countries: str,
        not_countries: str,
        not_author_name: str,
        parent_url: str,
        all_links: str,
        all_domain_links: str,
        iptc_tags: str,
        not_iptc_tags: str,
        source_name: str,
        iab_tags: str,
        not_iab_tags: str,
        news_domain_type: str,
        news_type: str,
        search_in: typing.Optional[str] = None,
        from_: typing.Optional[str] = None,
        to: typing.Optional[str] = None,
        published_date_precision: typing.Optional[str] = None,
        by_parse_date: typing.Optional[str] = None,
        sort_by: typing.Optional[str] = None,
        ranked_only: typing.Optional[str] = None,
        from_rank: typing.Optional[str] = None,
        to_rank: typing.Optional[str] = None,
        is_headline: typing.Optional[str] = None,
        is_opinion: typing.Optional[str] = None,
        is_paid_content: typing.Optional[str] = None,
        word_count_min: typing.Optional[str] = None,
        word_count_max: typing.Optional[str] = None,
        page: typing.Optional[str] = None,
        page_size: typing.Optional[str] = None,
        clustering_variable: typing.Optional[str] = None,
        clustering_enabled: typing.Optional[str] = None,
        clustering_threshold: typing.Optional[float] = None,
        include_nlp_data: typing.Optional[str] = None,
        has_nlp: typing.Optional[bool] = None,
        theme: typing.Optional[str] = None,
        not_theme: typing.Optional[str] = None,
        org_entity_name: typing.Optional[str] = None,
        per_entity_name: typing.Optional[str] = None,
        loc_entity_name: typing.Optional[str] = None,
        misc_entity_name: typing.Optional[str] = None,
        title_sentiment_min: typing.Optional[float] = None,
        title_sentiment_max: typing.Optional[float] = None,
        content_sentiment_min: typing.Optional[float] = None,
        content_sentiment_max: typing.Optional[float] = None,
        exclude_duplicates: typing.Optional[bool] = None,
        additional_domain_info: typing.Optional[bool] = None,
        is_news_domain: typing.Optional[bool] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> SearchGetResponse:
        """
        This endpoint allows you to search for articles. You can search for articles by keyword, language, country, source, and more.

        Parameters
        ----------
        q : str

        predefined_sources : str

        sources : str

        not_sources : str

        lang : str

        not_lang : str

        countries : str

        not_countries : str

        not_author_name : str

        parent_url : str

        all_links : str

        all_domain_links : str

        iptc_tags : str

        not_iptc_tags : str

        source_name : str

        iab_tags : str

        not_iab_tags : str

        news_domain_type : str

        news_type : str

        search_in : typing.Optional[str]

        from_ : typing.Optional[str]

        to : typing.Optional[str]

        published_date_precision : typing.Optional[str]

        by_parse_date : typing.Optional[str]

        sort_by : typing.Optional[str]

        ranked_only : typing.Optional[str]

        from_rank : typing.Optional[str]

        to_rank : typing.Optional[str]

        is_headline : typing.Optional[str]

        is_opinion : typing.Optional[str]

        is_paid_content : typing.Optional[str]

        word_count_min : typing.Optional[str]

        word_count_max : typing.Optional[str]

        page : typing.Optional[str]

        page_size : typing.Optional[str]

        clustering_variable : typing.Optional[str]

        clustering_enabled : typing.Optional[str]

        clustering_threshold : typing.Optional[float]

        include_nlp_data : typing.Optional[str]

        has_nlp : typing.Optional[bool]

        theme : typing.Optional[str]

        not_theme : typing.Optional[str]

        org_entity_name : typing.Optional[str]

        per_entity_name : typing.Optional[str]

        loc_entity_name : typing.Optional[str]

        misc_entity_name : typing.Optional[str]

        title_sentiment_min : typing.Optional[float]

        title_sentiment_max : typing.Optional[float]

        content_sentiment_min : typing.Optional[float]

        content_sentiment_max : typing.Optional[float]

        exclude_duplicates : typing.Optional[bool]

        additional_domain_info : typing.Optional[bool]

        is_news_domain : typing.Optional[bool]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        SearchGetResponse
            Successful Response

        Examples
        --------
        from newscatcher import NewscatcherApi

        client = NewscatcherApi(
            api_token="YOUR_API_TOKEN",
        )
        client.search.get(
            q="q",
            predefined_sources="predefined_sources",
            sources="sources",
            not_sources="not_sources",
            lang="lang",
            not_lang="not_lang",
            countries="countries",
            not_countries="not_countries",
            not_author_name="not_author_name",
            parent_url="parent_url",
            all_links="all_links",
            all_domain_links="all_domain_links",
            iptc_tags="iptc_tags",
            not_iptc_tags="not_iptc_tags",
            source_name="source_name",
            iab_tags="iab_tags",
            not_iab_tags="not_iab_tags",
            news_domain_type="news_domain_type",
            news_type="news_type",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            "api/search",
            method="GET",
            params={
                "q": q,
                "search_in": search_in,
                "predefined_sources": predefined_sources,
                "sources": sources,
                "not_sources": not_sources,
                "lang": lang,
                "not_lang": not_lang,
                "countries": countries,
                "not_countries": not_countries,
                "not_author_name": not_author_name,
                "from_": from_,
                "to_": to,
                "published_date_precision": published_date_precision,
                "by_parse_date": by_parse_date,
                "sort_by": sort_by,
                "ranked_only": ranked_only,
                "from_rank": from_rank,
                "to_rank": to_rank,
                "is_headline": is_headline,
                "is_opinion": is_opinion,
                "is_paid_content": is_paid_content,
                "parent_url": parent_url,
                "all_links": all_links,
                "all_domain_links": all_domain_links,
                "word_count_min": word_count_min,
                "word_count_max": word_count_max,
                "page": page,
                "page_size": page_size,
                "clustering_variable": clustering_variable,
                "clustering_enabled": clustering_enabled,
                "clustering_threshold": clustering_threshold,
                "include_nlp_data": include_nlp_data,
                "has_nlp": has_nlp,
                "theme": theme,
                "not_theme": not_theme,
                "ORG_entity_name": org_entity_name,
                "PER_entity_name": per_entity_name,
                "LOC_entity_name": loc_entity_name,
                "MISC_entity_name": misc_entity_name,
                "title_sentiment_min": title_sentiment_min,
                "title_sentiment_max": title_sentiment_max,
                "content_sentiment_min": content_sentiment_min,
                "content_sentiment_max": content_sentiment_max,
                "iptc_tags": iptc_tags,
                "not_iptc_tags": not_iptc_tags,
                "source_name": source_name,
                "iab_tags": iab_tags,
                "not_iab_tags": not_iab_tags,
                "exclude_duplicates": exclude_duplicates,
                "additional_domain_info": additional_domain_info,
                "is_news_domain": is_news_domain,
                "news_domain_type": news_domain_type,
                "news_type": news_type,
            },
            request_options=request_options,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    SearchGetResponse,
                    parse_obj_as(
                        type_=SearchGetResponse,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    typing.cast(
                        HttpValidationError,
                        parse_obj_as(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def post(
        self,
        *,
        q: str,
        search_in: typing.Optional[str] = OMIT,
        predefined_sources: typing.Optional[typing.Optional[typing.Any]] = OMIT,
        sources: typing.Optional[typing.Optional[typing.Any]] = OMIT,
        not_sources: typing.Optional[typing.Optional[typing.Any]] = OMIT,
        lang: typing.Optional[typing.Optional[typing.Any]] = OMIT,
        not_lang: typing.Optional[typing.Optional[typing.Any]] = OMIT,
        countries: typing.Optional[typing.Optional[typing.Any]] = OMIT,
        not_countries: typing.Optional[typing.Optional[typing.Any]] = OMIT,
        not_author_name: typing.Optional[typing.Optional[typing.Any]] = OMIT,
        from_: typing.Optional[SearchRequestFrom] = OMIT,
        to: typing.Optional[SearchRequestTo] = OMIT,
        published_date_precision: typing.Optional[str] = OMIT,
        by_parse_date: typing.Optional[SearchRequestByParseDate] = OMIT,
        sort_by: typing.Optional[str] = OMIT,
        ranked_only: typing.Optional[SearchRequestRankedOnly] = OMIT,
        from_rank: typing.Optional[SearchRequestFromRank] = OMIT,
        to_rank: typing.Optional[SearchRequestToRank] = OMIT,
        is_headline: typing.Optional[SearchRequestIsHeadline] = OMIT,
        is_opinion: typing.Optional[SearchRequestIsOpinion] = OMIT,
        is_paid_content: typing.Optional[SearchRequestIsPaidContent] = OMIT,
        parent_url: typing.Optional[typing.Optional[typing.Any]] = OMIT,
        all_links: typing.Optional[typing.Optional[typing.Any]] = OMIT,
        all_domain_links: typing.Optional[typing.Optional[typing.Any]] = OMIT,
        word_count_min: typing.Optional[SearchRequestWordCountMin] = OMIT,
        word_count_max: typing.Optional[SearchRequestWordCountMax] = OMIT,
        page: typing.Optional[SearchRequestPage] = OMIT,
        page_size: typing.Optional[SearchRequestPageSize] = OMIT,
        clustering_variable: typing.Optional[str] = OMIT,
        clustering_enabled: typing.Optional[SearchRequestClusteringEnabled] = OMIT,
        clustering_threshold: typing.Optional[SearchRequestClusteringThreshold] = OMIT,
        include_nlp_data: typing.Optional[SearchRequestIncludeNlpData] = OMIT,
        has_nlp: typing.Optional[bool] = OMIT,
        theme: typing.Optional[str] = OMIT,
        not_theme: typing.Optional[str] = OMIT,
        org_entity_name: typing.Optional[str] = OMIT,
        per_entity_name: typing.Optional[str] = OMIT,
        loc_entity_name: typing.Optional[str] = OMIT,
        misc_entity_name: typing.Optional[str] = OMIT,
        title_sentiment_min: typing.Optional[float] = OMIT,
        title_sentiment_max: typing.Optional[float] = OMIT,
        content_sentiment_min: typing.Optional[float] = OMIT,
        content_sentiment_max: typing.Optional[float] = OMIT,
        iptc_tags: typing.Optional[typing.Optional[typing.Any]] = OMIT,
        not_iptc_tags: typing.Optional[typing.Optional[typing.Any]] = OMIT,
        source_name: typing.Optional[typing.Optional[typing.Any]] = OMIT,
        iab_tags: typing.Optional[typing.Optional[typing.Any]] = OMIT,
        not_iab_tags: typing.Optional[typing.Optional[typing.Any]] = OMIT,
        exclude_duplicates: typing.Optional[bool] = OMIT,
        additional_domain_info: typing.Optional[bool] = OMIT,
        is_news_domain: typing.Optional[bool] = OMIT,
        news_domain_type: typing.Optional[typing.Optional[typing.Any]] = OMIT,
        news_type: typing.Optional[typing.Optional[typing.Any]] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> SearchPostResponse:
        """
        This endpoint allows you to search for articles. You can search for articles by keyword, language, country, source, and more.

        Parameters
        ----------
        q : str

        search_in : typing.Optional[str]

        predefined_sources : typing.Optional[typing.Optional[typing.Any]]

        sources : typing.Optional[typing.Optional[typing.Any]]

        not_sources : typing.Optional[typing.Optional[typing.Any]]

        lang : typing.Optional[typing.Optional[typing.Any]]

        not_lang : typing.Optional[typing.Optional[typing.Any]]

        countries : typing.Optional[typing.Optional[typing.Any]]

        not_countries : typing.Optional[typing.Optional[typing.Any]]

        not_author_name : typing.Optional[typing.Optional[typing.Any]]

        from_ : typing.Optional[SearchRequestFrom]

        to : typing.Optional[SearchRequestTo]

        published_date_precision : typing.Optional[str]

        by_parse_date : typing.Optional[SearchRequestByParseDate]

        sort_by : typing.Optional[str]

        ranked_only : typing.Optional[SearchRequestRankedOnly]

        from_rank : typing.Optional[SearchRequestFromRank]

        to_rank : typing.Optional[SearchRequestToRank]

        is_headline : typing.Optional[SearchRequestIsHeadline]

        is_opinion : typing.Optional[SearchRequestIsOpinion]

        is_paid_content : typing.Optional[SearchRequestIsPaidContent]

        parent_url : typing.Optional[typing.Optional[typing.Any]]

        all_links : typing.Optional[typing.Optional[typing.Any]]

        all_domain_links : typing.Optional[typing.Optional[typing.Any]]

        word_count_min : typing.Optional[SearchRequestWordCountMin]

        word_count_max : typing.Optional[SearchRequestWordCountMax]

        page : typing.Optional[SearchRequestPage]

        page_size : typing.Optional[SearchRequestPageSize]

        clustering_variable : typing.Optional[str]

        clustering_enabled : typing.Optional[SearchRequestClusteringEnabled]

        clustering_threshold : typing.Optional[SearchRequestClusteringThreshold]

        include_nlp_data : typing.Optional[SearchRequestIncludeNlpData]

        has_nlp : typing.Optional[bool]

        theme : typing.Optional[str]

        not_theme : typing.Optional[str]

        org_entity_name : typing.Optional[str]

        per_entity_name : typing.Optional[str]

        loc_entity_name : typing.Optional[str]

        misc_entity_name : typing.Optional[str]

        title_sentiment_min : typing.Optional[float]

        title_sentiment_max : typing.Optional[float]

        content_sentiment_min : typing.Optional[float]

        content_sentiment_max : typing.Optional[float]

        iptc_tags : typing.Optional[typing.Optional[typing.Any]]

        not_iptc_tags : typing.Optional[typing.Optional[typing.Any]]

        source_name : typing.Optional[typing.Optional[typing.Any]]

        iab_tags : typing.Optional[typing.Optional[typing.Any]]

        not_iab_tags : typing.Optional[typing.Optional[typing.Any]]

        exclude_duplicates : typing.Optional[bool]

        additional_domain_info : typing.Optional[bool]

        is_news_domain : typing.Optional[bool]

        news_domain_type : typing.Optional[typing.Optional[typing.Any]]

        news_type : typing.Optional[typing.Optional[typing.Any]]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        SearchPostResponse
            Successful Response

        Examples
        --------
        from newscatcher import NewscatcherApi

        client = NewscatcherApi(
            api_token="YOUR_API_TOKEN",
        )
        client.search.post(
            q="q",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            "api/search",
            method="POST",
            json={
                "q": q,
                "search_in": search_in,
                "predefined_sources": predefined_sources,
                "sources": sources,
                "not_sources": not_sources,
                "lang": lang,
                "not_lang": not_lang,
                "countries": countries,
                "not_countries": not_countries,
                "not_author_name": not_author_name,
                "from_": convert_and_respect_annotation_metadata(
                    object_=from_, annotation=SearchRequestFrom, direction="write"
                ),
                "to_": convert_and_respect_annotation_metadata(
                    object_=to, annotation=SearchRequestTo, direction="write"
                ),
                "published_date_precision": published_date_precision,
                "by_parse_date": convert_and_respect_annotation_metadata(
                    object_=by_parse_date, annotation=SearchRequestByParseDate, direction="write"
                ),
                "sort_by": sort_by,
                "ranked_only": convert_and_respect_annotation_metadata(
                    object_=ranked_only, annotation=SearchRequestRankedOnly, direction="write"
                ),
                "from_rank": convert_and_respect_annotation_metadata(
                    object_=from_rank, annotation=SearchRequestFromRank, direction="write"
                ),
                "to_rank": convert_and_respect_annotation_metadata(
                    object_=to_rank, annotation=SearchRequestToRank, direction="write"
                ),
                "is_headline": convert_and_respect_annotation_metadata(
                    object_=is_headline, annotation=SearchRequestIsHeadline, direction="write"
                ),
                "is_opinion": convert_and_respect_annotation_metadata(
                    object_=is_opinion, annotation=SearchRequestIsOpinion, direction="write"
                ),
                "is_paid_content": convert_and_respect_annotation_metadata(
                    object_=is_paid_content, annotation=SearchRequestIsPaidContent, direction="write"
                ),
                "parent_url": parent_url,
                "all_links": all_links,
                "all_domain_links": all_domain_links,
                "word_count_min": convert_and_respect_annotation_metadata(
                    object_=word_count_min, annotation=SearchRequestWordCountMin, direction="write"
                ),
                "word_count_max": convert_and_respect_annotation_metadata(
                    object_=word_count_max, annotation=SearchRequestWordCountMax, direction="write"
                ),
                "page": convert_and_respect_annotation_metadata(
                    object_=page, annotation=SearchRequestPage, direction="write"
                ),
                "page_size": convert_and_respect_annotation_metadata(
                    object_=page_size, annotation=SearchRequestPageSize, direction="write"
                ),
                "clustering_variable": clustering_variable,
                "clustering_enabled": convert_and_respect_annotation_metadata(
                    object_=clustering_enabled, annotation=SearchRequestClusteringEnabled, direction="write"
                ),
                "clustering_threshold": convert_and_respect_annotation_metadata(
                    object_=clustering_threshold, annotation=SearchRequestClusteringThreshold, direction="write"
                ),
                "include_nlp_data": convert_and_respect_annotation_metadata(
                    object_=include_nlp_data, annotation=SearchRequestIncludeNlpData, direction="write"
                ),
                "has_nlp": has_nlp,
                "theme": theme,
                "not_theme": not_theme,
                "ORG_entity_name": org_entity_name,
                "PER_entity_name": per_entity_name,
                "LOC_entity_name": loc_entity_name,
                "MISC_entity_name": misc_entity_name,
                "title_sentiment_min": title_sentiment_min,
                "title_sentiment_max": title_sentiment_max,
                "content_sentiment_min": content_sentiment_min,
                "content_sentiment_max": content_sentiment_max,
                "iptc_tags": iptc_tags,
                "not_iptc_tags": not_iptc_tags,
                "source_name": source_name,
                "iab_tags": iab_tags,
                "not_iab_tags": not_iab_tags,
                "exclude_duplicates": exclude_duplicates,
                "additional_domain_info": additional_domain_info,
                "is_news_domain": is_news_domain,
                "news_domain_type": news_domain_type,
                "news_type": news_type,
            },
            headers={
                "content-type": "application/json",
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    SearchPostResponse,
                    parse_obj_as(
                        type_=SearchPostResponse,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    typing.cast(
                        HttpValidationError,
                        parse_obj_as(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)


class AsyncSearchClient:
    def __init__(self, *, client_wrapper: AsyncClientWrapper):
        self._client_wrapper = client_wrapper

    async def get(
        self,
        *,
        q: str,
        predefined_sources: str,
        sources: str,
        not_sources: str,
        lang: str,
        not_lang: str,
        countries: str,
        not_countries: str,
        not_author_name: str,
        parent_url: str,
        all_links: str,
        all_domain_links: str,
        iptc_tags: str,
        not_iptc_tags: str,
        source_name: str,
        iab_tags: str,
        not_iab_tags: str,
        news_domain_type: str,
        news_type: str,
        search_in: typing.Optional[str] = None,
        from_: typing.Optional[str] = None,
        to: typing.Optional[str] = None,
        published_date_precision: typing.Optional[str] = None,
        by_parse_date: typing.Optional[str] = None,
        sort_by: typing.Optional[str] = None,
        ranked_only: typing.Optional[str] = None,
        from_rank: typing.Optional[str] = None,
        to_rank: typing.Optional[str] = None,
        is_headline: typing.Optional[str] = None,
        is_opinion: typing.Optional[str] = None,
        is_paid_content: typing.Optional[str] = None,
        word_count_min: typing.Optional[str] = None,
        word_count_max: typing.Optional[str] = None,
        page: typing.Optional[str] = None,
        page_size: typing.Optional[str] = None,
        clustering_variable: typing.Optional[str] = None,
        clustering_enabled: typing.Optional[str] = None,
        clustering_threshold: typing.Optional[float] = None,
        include_nlp_data: typing.Optional[str] = None,
        has_nlp: typing.Optional[bool] = None,
        theme: typing.Optional[str] = None,
        not_theme: typing.Optional[str] = None,
        org_entity_name: typing.Optional[str] = None,
        per_entity_name: typing.Optional[str] = None,
        loc_entity_name: typing.Optional[str] = None,
        misc_entity_name: typing.Optional[str] = None,
        title_sentiment_min: typing.Optional[float] = None,
        title_sentiment_max: typing.Optional[float] = None,
        content_sentiment_min: typing.Optional[float] = None,
        content_sentiment_max: typing.Optional[float] = None,
        exclude_duplicates: typing.Optional[bool] = None,
        additional_domain_info: typing.Optional[bool] = None,
        is_news_domain: typing.Optional[bool] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> SearchGetResponse:
        """
        This endpoint allows you to search for articles. You can search for articles by keyword, language, country, source, and more.

        Parameters
        ----------
        q : str

        predefined_sources : str

        sources : str

        not_sources : str

        lang : str

        not_lang : str

        countries : str

        not_countries : str

        not_author_name : str

        parent_url : str

        all_links : str

        all_domain_links : str

        iptc_tags : str

        not_iptc_tags : str

        source_name : str

        iab_tags : str

        not_iab_tags : str

        news_domain_type : str

        news_type : str

        search_in : typing.Optional[str]

        from_ : typing.Optional[str]

        to : typing.Optional[str]

        published_date_precision : typing.Optional[str]

        by_parse_date : typing.Optional[str]

        sort_by : typing.Optional[str]

        ranked_only : typing.Optional[str]

        from_rank : typing.Optional[str]

        to_rank : typing.Optional[str]

        is_headline : typing.Optional[str]

        is_opinion : typing.Optional[str]

        is_paid_content : typing.Optional[str]

        word_count_min : typing.Optional[str]

        word_count_max : typing.Optional[str]

        page : typing.Optional[str]

        page_size : typing.Optional[str]

        clustering_variable : typing.Optional[str]

        clustering_enabled : typing.Optional[str]

        clustering_threshold : typing.Optional[float]

        include_nlp_data : typing.Optional[str]

        has_nlp : typing.Optional[bool]

        theme : typing.Optional[str]

        not_theme : typing.Optional[str]

        org_entity_name : typing.Optional[str]

        per_entity_name : typing.Optional[str]

        loc_entity_name : typing.Optional[str]

        misc_entity_name : typing.Optional[str]

        title_sentiment_min : typing.Optional[float]

        title_sentiment_max : typing.Optional[float]

        content_sentiment_min : typing.Optional[float]

        content_sentiment_max : typing.Optional[float]

        exclude_duplicates : typing.Optional[bool]

        additional_domain_info : typing.Optional[bool]

        is_news_domain : typing.Optional[bool]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        SearchGetResponse
            Successful Response

        Examples
        --------
        import asyncio

        from newscatcher import AsyncNewscatcherApi

        client = AsyncNewscatcherApi(
            api_token="YOUR_API_TOKEN",
        )


        async def main() -> None:
            await client.search.get(
                q="q",
                predefined_sources="predefined_sources",
                sources="sources",
                not_sources="not_sources",
                lang="lang",
                not_lang="not_lang",
                countries="countries",
                not_countries="not_countries",
                not_author_name="not_author_name",
                parent_url="parent_url",
                all_links="all_links",
                all_domain_links="all_domain_links",
                iptc_tags="iptc_tags",
                not_iptc_tags="not_iptc_tags",
                source_name="source_name",
                iab_tags="iab_tags",
                not_iab_tags="not_iab_tags",
                news_domain_type="news_domain_type",
                news_type="news_type",
            )


        asyncio.run(main())
        """
        _response = await self._client_wrapper.httpx_client.request(
            "api/search",
            method="GET",
            params={
                "q": q,
                "search_in": search_in,
                "predefined_sources": predefined_sources,
                "sources": sources,
                "not_sources": not_sources,
                "lang": lang,
                "not_lang": not_lang,
                "countries": countries,
                "not_countries": not_countries,
                "not_author_name": not_author_name,
                "from_": from_,
                "to_": to,
                "published_date_precision": published_date_precision,
                "by_parse_date": by_parse_date,
                "sort_by": sort_by,
                "ranked_only": ranked_only,
                "from_rank": from_rank,
                "to_rank": to_rank,
                "is_headline": is_headline,
                "is_opinion": is_opinion,
                "is_paid_content": is_paid_content,
                "parent_url": parent_url,
                "all_links": all_links,
                "all_domain_links": all_domain_links,
                "word_count_min": word_count_min,
                "word_count_max": word_count_max,
                "page": page,
                "page_size": page_size,
                "clustering_variable": clustering_variable,
                "clustering_enabled": clustering_enabled,
                "clustering_threshold": clustering_threshold,
                "include_nlp_data": include_nlp_data,
                "has_nlp": has_nlp,
                "theme": theme,
                "not_theme": not_theme,
                "ORG_entity_name": org_entity_name,
                "PER_entity_name": per_entity_name,
                "LOC_entity_name": loc_entity_name,
                "MISC_entity_name": misc_entity_name,
                "title_sentiment_min": title_sentiment_min,
                "title_sentiment_max": title_sentiment_max,
                "content_sentiment_min": content_sentiment_min,
                "content_sentiment_max": content_sentiment_max,
                "iptc_tags": iptc_tags,
                "not_iptc_tags": not_iptc_tags,
                "source_name": source_name,
                "iab_tags": iab_tags,
                "not_iab_tags": not_iab_tags,
                "exclude_duplicates": exclude_duplicates,
                "additional_domain_info": additional_domain_info,
                "is_news_domain": is_news_domain,
                "news_domain_type": news_domain_type,
                "news_type": news_type,
            },
            request_options=request_options,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    SearchGetResponse,
                    parse_obj_as(
                        type_=SearchGetResponse,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    typing.cast(
                        HttpValidationError,
                        parse_obj_as(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def post(
        self,
        *,
        q: str,
        search_in: typing.Optional[str] = OMIT,
        predefined_sources: typing.Optional[typing.Optional[typing.Any]] = OMIT,
        sources: typing.Optional[typing.Optional[typing.Any]] = OMIT,
        not_sources: typing.Optional[typing.Optional[typing.Any]] = OMIT,
        lang: typing.Optional[typing.Optional[typing.Any]] = OMIT,
        not_lang: typing.Optional[typing.Optional[typing.Any]] = OMIT,
        countries: typing.Optional[typing.Optional[typing.Any]] = OMIT,
        not_countries: typing.Optional[typing.Optional[typing.Any]] = OMIT,
        not_author_name: typing.Optional[typing.Optional[typing.Any]] = OMIT,
        from_: typing.Optional[SearchRequestFrom] = OMIT,
        to: typing.Optional[SearchRequestTo] = OMIT,
        published_date_precision: typing.Optional[str] = OMIT,
        by_parse_date: typing.Optional[SearchRequestByParseDate] = OMIT,
        sort_by: typing.Optional[str] = OMIT,
        ranked_only: typing.Optional[SearchRequestRankedOnly] = OMIT,
        from_rank: typing.Optional[SearchRequestFromRank] = OMIT,
        to_rank: typing.Optional[SearchRequestToRank] = OMIT,
        is_headline: typing.Optional[SearchRequestIsHeadline] = OMIT,
        is_opinion: typing.Optional[SearchRequestIsOpinion] = OMIT,
        is_paid_content: typing.Optional[SearchRequestIsPaidContent] = OMIT,
        parent_url: typing.Optional[typing.Optional[typing.Any]] = OMIT,
        all_links: typing.Optional[typing.Optional[typing.Any]] = OMIT,
        all_domain_links: typing.Optional[typing.Optional[typing.Any]] = OMIT,
        word_count_min: typing.Optional[SearchRequestWordCountMin] = OMIT,
        word_count_max: typing.Optional[SearchRequestWordCountMax] = OMIT,
        page: typing.Optional[SearchRequestPage] = OMIT,
        page_size: typing.Optional[SearchRequestPageSize] = OMIT,
        clustering_variable: typing.Optional[str] = OMIT,
        clustering_enabled: typing.Optional[SearchRequestClusteringEnabled] = OMIT,
        clustering_threshold: typing.Optional[SearchRequestClusteringThreshold] = OMIT,
        include_nlp_data: typing.Optional[SearchRequestIncludeNlpData] = OMIT,
        has_nlp: typing.Optional[bool] = OMIT,
        theme: typing.Optional[str] = OMIT,
        not_theme: typing.Optional[str] = OMIT,
        org_entity_name: typing.Optional[str] = OMIT,
        per_entity_name: typing.Optional[str] = OMIT,
        loc_entity_name: typing.Optional[str] = OMIT,
        misc_entity_name: typing.Optional[str] = OMIT,
        title_sentiment_min: typing.Optional[float] = OMIT,
        title_sentiment_max: typing.Optional[float] = OMIT,
        content_sentiment_min: typing.Optional[float] = OMIT,
        content_sentiment_max: typing.Optional[float] = OMIT,
        iptc_tags: typing.Optional[typing.Optional[typing.Any]] = OMIT,
        not_iptc_tags: typing.Optional[typing.Optional[typing.Any]] = OMIT,
        source_name: typing.Optional[typing.Optional[typing.Any]] = OMIT,
        iab_tags: typing.Optional[typing.Optional[typing.Any]] = OMIT,
        not_iab_tags: typing.Optional[typing.Optional[typing.Any]] = OMIT,
        exclude_duplicates: typing.Optional[bool] = OMIT,
        additional_domain_info: typing.Optional[bool] = OMIT,
        is_news_domain: typing.Optional[bool] = OMIT,
        news_domain_type: typing.Optional[typing.Optional[typing.Any]] = OMIT,
        news_type: typing.Optional[typing.Optional[typing.Any]] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> SearchPostResponse:
        """
        This endpoint allows you to search for articles. You can search for articles by keyword, language, country, source, and more.

        Parameters
        ----------
        q : str

        search_in : typing.Optional[str]

        predefined_sources : typing.Optional[typing.Optional[typing.Any]]

        sources : typing.Optional[typing.Optional[typing.Any]]

        not_sources : typing.Optional[typing.Optional[typing.Any]]

        lang : typing.Optional[typing.Optional[typing.Any]]

        not_lang : typing.Optional[typing.Optional[typing.Any]]

        countries : typing.Optional[typing.Optional[typing.Any]]

        not_countries : typing.Optional[typing.Optional[typing.Any]]

        not_author_name : typing.Optional[typing.Optional[typing.Any]]

        from_ : typing.Optional[SearchRequestFrom]

        to : typing.Optional[SearchRequestTo]

        published_date_precision : typing.Optional[str]

        by_parse_date : typing.Optional[SearchRequestByParseDate]

        sort_by : typing.Optional[str]

        ranked_only : typing.Optional[SearchRequestRankedOnly]

        from_rank : typing.Optional[SearchRequestFromRank]

        to_rank : typing.Optional[SearchRequestToRank]

        is_headline : typing.Optional[SearchRequestIsHeadline]

        is_opinion : typing.Optional[SearchRequestIsOpinion]

        is_paid_content : typing.Optional[SearchRequestIsPaidContent]

        parent_url : typing.Optional[typing.Optional[typing.Any]]

        all_links : typing.Optional[typing.Optional[typing.Any]]

        all_domain_links : typing.Optional[typing.Optional[typing.Any]]

        word_count_min : typing.Optional[SearchRequestWordCountMin]

        word_count_max : typing.Optional[SearchRequestWordCountMax]

        page : typing.Optional[SearchRequestPage]

        page_size : typing.Optional[SearchRequestPageSize]

        clustering_variable : typing.Optional[str]

        clustering_enabled : typing.Optional[SearchRequestClusteringEnabled]

        clustering_threshold : typing.Optional[SearchRequestClusteringThreshold]

        include_nlp_data : typing.Optional[SearchRequestIncludeNlpData]

        has_nlp : typing.Optional[bool]

        theme : typing.Optional[str]

        not_theme : typing.Optional[str]

        org_entity_name : typing.Optional[str]

        per_entity_name : typing.Optional[str]

        loc_entity_name : typing.Optional[str]

        misc_entity_name : typing.Optional[str]

        title_sentiment_min : typing.Optional[float]

        title_sentiment_max : typing.Optional[float]

        content_sentiment_min : typing.Optional[float]

        content_sentiment_max : typing.Optional[float]

        iptc_tags : typing.Optional[typing.Optional[typing.Any]]

        not_iptc_tags : typing.Optional[typing.Optional[typing.Any]]

        source_name : typing.Optional[typing.Optional[typing.Any]]

        iab_tags : typing.Optional[typing.Optional[typing.Any]]

        not_iab_tags : typing.Optional[typing.Optional[typing.Any]]

        exclude_duplicates : typing.Optional[bool]

        additional_domain_info : typing.Optional[bool]

        is_news_domain : typing.Optional[bool]

        news_domain_type : typing.Optional[typing.Optional[typing.Any]]

        news_type : typing.Optional[typing.Optional[typing.Any]]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        SearchPostResponse
            Successful Response

        Examples
        --------
        import asyncio

        from newscatcher import AsyncNewscatcherApi

        client = AsyncNewscatcherApi(
            api_token="YOUR_API_TOKEN",
        )


        async def main() -> None:
            await client.search.post(
                q="q",
            )


        asyncio.run(main())
        """
        _response = await self._client_wrapper.httpx_client.request(
            "api/search",
            method="POST",
            json={
                "q": q,
                "search_in": search_in,
                "predefined_sources": predefined_sources,
                "sources": sources,
                "not_sources": not_sources,
                "lang": lang,
                "not_lang": not_lang,
                "countries": countries,
                "not_countries": not_countries,
                "not_author_name": not_author_name,
                "from_": convert_and_respect_annotation_metadata(
                    object_=from_, annotation=SearchRequestFrom, direction="write"
                ),
                "to_": convert_and_respect_annotation_metadata(
                    object_=to, annotation=SearchRequestTo, direction="write"
                ),
                "published_date_precision": published_date_precision,
                "by_parse_date": convert_and_respect_annotation_metadata(
                    object_=by_parse_date, annotation=SearchRequestByParseDate, direction="write"
                ),
                "sort_by": sort_by,
                "ranked_only": convert_and_respect_annotation_metadata(
                    object_=ranked_only, annotation=SearchRequestRankedOnly, direction="write"
                ),
                "from_rank": convert_and_respect_annotation_metadata(
                    object_=from_rank, annotation=SearchRequestFromRank, direction="write"
                ),
                "to_rank": convert_and_respect_annotation_metadata(
                    object_=to_rank, annotation=SearchRequestToRank, direction="write"
                ),
                "is_headline": convert_and_respect_annotation_metadata(
                    object_=is_headline, annotation=SearchRequestIsHeadline, direction="write"
                ),
                "is_opinion": convert_and_respect_annotation_metadata(
                    object_=is_opinion, annotation=SearchRequestIsOpinion, direction="write"
                ),
                "is_paid_content": convert_and_respect_annotation_metadata(
                    object_=is_paid_content, annotation=SearchRequestIsPaidContent, direction="write"
                ),
                "parent_url": parent_url,
                "all_links": all_links,
                "all_domain_links": all_domain_links,
                "word_count_min": convert_and_respect_annotation_metadata(
                    object_=word_count_min, annotation=SearchRequestWordCountMin, direction="write"
                ),
                "word_count_max": convert_and_respect_annotation_metadata(
                    object_=word_count_max, annotation=SearchRequestWordCountMax, direction="write"
                ),
                "page": convert_and_respect_annotation_metadata(
                    object_=page, annotation=SearchRequestPage, direction="write"
                ),
                "page_size": convert_and_respect_annotation_metadata(
                    object_=page_size, annotation=SearchRequestPageSize, direction="write"
                ),
                "clustering_variable": clustering_variable,
                "clustering_enabled": convert_and_respect_annotation_metadata(
                    object_=clustering_enabled, annotation=SearchRequestClusteringEnabled, direction="write"
                ),
                "clustering_threshold": convert_and_respect_annotation_metadata(
                    object_=clustering_threshold, annotation=SearchRequestClusteringThreshold, direction="write"
                ),
                "include_nlp_data": convert_and_respect_annotation_metadata(
                    object_=include_nlp_data, annotation=SearchRequestIncludeNlpData, direction="write"
                ),
                "has_nlp": has_nlp,
                "theme": theme,
                "not_theme": not_theme,
                "ORG_entity_name": org_entity_name,
                "PER_entity_name": per_entity_name,
                "LOC_entity_name": loc_entity_name,
                "MISC_entity_name": misc_entity_name,
                "title_sentiment_min": title_sentiment_min,
                "title_sentiment_max": title_sentiment_max,
                "content_sentiment_min": content_sentiment_min,
                "content_sentiment_max": content_sentiment_max,
                "iptc_tags": iptc_tags,
                "not_iptc_tags": not_iptc_tags,
                "source_name": source_name,
                "iab_tags": iab_tags,
                "not_iab_tags": not_iab_tags,
                "exclude_duplicates": exclude_duplicates,
                "additional_domain_info": additional_domain_info,
                "is_news_domain": is_news_domain,
                "news_domain_type": news_domain_type,
                "news_type": news_type,
            },
            headers={
                "content-type": "application/json",
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    SearchPostResponse,
                    parse_obj_as(
                        type_=SearchPostResponse,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    typing.cast(
                        HttpValidationError,
                        parse_obj_as(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)
