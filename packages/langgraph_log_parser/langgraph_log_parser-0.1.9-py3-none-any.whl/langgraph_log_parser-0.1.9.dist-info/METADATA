Metadata-Version: 2.1
Name: langgraph_log_parser
Version: 0.1.9
Summary: Parser for logs from LangGraph
Author: Tomasz SerafiÅ„ski
Author-email: tomasz@serafinski.net
Requires-Python: >=3.9,<4.0
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Classifier: Programming Language :: Python :: 3.13
Requires-Dist: langchain (>=0.3.7,<0.4.0)
Requires-Dist: langchain-community (>=0.3.5,<0.4.0)
Requires-Dist: langchain-core (>=0.3.15,<0.4.0)
Requires-Dist: langchain-experimental (>=0.3.3,<0.4.0)
Requires-Dist: langchain-openai (>=0.2.6,<0.3.0)
Requires-Dist: langgraph (>=0.2.45,<0.3.0)
Requires-Dist: langgraph-checkpoint-sqlite (>=2.0.1,<3.0.0)
Requires-Dist: langsmith (>=0.2.4,<0.3.0)
Requires-Dist: matplotlib (>=3.9.2,<4.0.0)
Requires-Dist: msgpack (>=1.1.0,<2.0.0)
Requires-Dist: numpy (<2.0.0)
Requires-Dist: pandas (>=2.2.3,<3.0.0)
Requires-Dist: pm4py (>=2.7.12.1,<3.0.0.0)
Requires-Dist: prefixspan (>=0.5.2,<0.6.0)
Requires-Dist: pydantic (>=2.9.2,<3.0.0)
Requires-Dist: python-dotenv (>=1.0.1,<2.0.0)
Requires-Dist: pyvis (>=0.3.2,<0.4.0)
Requires-Dist: tavily-python (>=0.5.0,<0.6.0)
Description-Content-Type: text/markdown

# LangGraph Log Parser
[![wakatime](https://wakatime.com/badge/user/c88d1b82-ebdd-4842-ad45-93f471842103/project/b6d31f0d-340f-42d5-aa2d-bf3e2e6a0370.svg)](https://wakatime.com/badge/user/c88d1b82-ebdd-4842-ad45-93f471842103/project/b6d31f0d-340f-42d5-aa2d-bf3e2e6a0370)

# Documentation
Documentation is available at: https://serafinski.github.io/LangGraph-Log-Parser/

# Purpose
This Python package facilitates the parsing of run logs generated by [LangGraph](https://langchain-ai.github.io/langgraph/). During execution, logs are stored in an SQLite database in an encoded format _(using msgpack)_. These logs are then decoded and exported to a `json` format. Subsequently, the `json` files are transformed into `csv` files for further analysis.

Once in `csv` format, the data can be analyzed using methods from the [py4pm](https://processintelligence.solutions/static/api/2.7.11/index.html) library. These methods calculate specific statistics related to the multi-agent infrastructure's performance and enable visualizations of the process behavior and execution flow.

This pipeline provides a streamlined approach for extracting, transforming, and analyzing logs, offering valuable insights into multi-agent systems.

# Installation
This package requires Python 3.9 or higher.

If you would like to develop this package, use Python 3.10 - since 3.10 is the needed minimum by Sphinx.
## Prerequisites
This package requires Graphviz to be installed on your system.

### Windows
Download the Graphviz installer from the [Graphviz website](https://graphviz.org/download/).

### macOS
Install Graphviz using Homebrew:
```dotenv
brew install graphviz
```

### Linux
For Debian, Ubuntu, use the following command:
```dotenv
sudo apt-get install graphviz
```
<br>

For Fedora, Rocky Linux, RHEL or CentOS use the following command:
```dotenv
sudo dnf install graphviz
```

## Environment setup
To create virtual environment (using conda), use the following commands:
```dotenv
conda create -n langgraph_log_parser python=3.9
conda activate langgraph_log_parser
pip install langgraph_log_parser
```
# Basic Example
This example is based on the [Building a Basic Chatbot](https://langchain-ai.github.io/langgraph/tutorials/introduction/#part-1-build-a-basic-chatbot) from LangGraph documentation.
```python
import sqlite3

from dotenv import load_dotenv
from typing import Annotated

from langgraph.checkpoint.sqlite import SqliteSaver
from typing_extensions import TypedDict
from langchain_openai import ChatOpenAI
from langgraph.graph import StateGraph, START, END
from langgraph.graph.message import add_messages

from langgraph_log_parser import *

exp = create_experiment("main")

load_dotenv()

conn = sqlite3.connect(exp.database, check_same_thread=False)
memory = SqliteSaver(conn)

class State(TypedDict):
    messages: Annotated[list, add_messages]

graph_builder = StateGraph(State)

llm = ChatOpenAI(model="gpt-4o-mini")

def chatbot(state: State):
    return {"messages": [llm.invoke(state["messages"])]}

graph_builder.add_node("chatbot_node", chatbot)

graph_builder.add_edge(START, "chatbot_node")
graph_builder.add_edge("chatbot_node", END)

graph = graph_builder.compile(checkpointer=memory)

run_multiple_iterations(graph, 1, 5, {"messages": [("user", "Tell me a joke")]})

export_sqlite_to_jsons(exp.database, exp.json_dir)

graph_config = GraphConfig(
    nodes=["chatbot_node"]
)

export_jsons_to_csv(exp.json_dir, exp.get_csv_path(), graph_config)

print()
event_log = load_event_log(exp.get_csv_path())
print_analysis(event_log)

generate_reports(event_log, exp.reports_dir)

generate_visualizations(event_log, graph, exp.img_dir)
```
