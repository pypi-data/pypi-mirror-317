Metadata-Version: 2.1
Name: wirtual-plugins-openai
Version: 0.0.2
Summary: Agent Framework plugin for services from OpenAI
Home-page: https://github.com/wirtualdev/wirtual-agents
License: Apache-2.0
Project-URL: Documentation, https://docs.wirtual.dev
Project-URL: Website, https://wirtual.dev/
Project-URL: Source, https://github.com/wirtualdev/wirtual-agents
Keywords: webrtc,realtime,audio,video,wirtual
Classifier: Intended Audience :: Developers
Classifier: License :: OSI Approved :: Apache Software License
Classifier: Topic :: Multimedia :: Sound/Audio
Classifier: Topic :: Multimedia :: Video
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3 :: Only
Requires-Python: >=3.9.0
Description-Content-Type: text/markdown
Requires-Dist: wirtual-agents[codecs,images]>=0.0.1
Requires-Dist: openai>=1.50
Provides-Extra: vertex
Requires-Dist: google-auth>=2.0.0; extra == "vertex"

# LiveKit Plugins OpenAI

Agent Framework plugin for services from OpenAI. Currently supports STT, TTS, and Dalle 3.

## Installation

```bash
pip install wirtual-plugins-openai
```

## Pre-requisites

You'll need an API key from OpenAI. It can be set as an environment variable: `OPENAI_API_KEY`

## OpenAI Beta Features

### Assistants API

In addition to LLM, STT, and TTS, this package also supports using [OpenAI's Assistants API](https://platform.openai.com/docs/assistants/overview) as a LLM.

The Assistants API is a stateful API that holds the conversation state on the server-side.

The `AssistantLLM` class gives you a LLM-like interface to interact with the Assistant API.

For examples of using Assistants API with VoicePipelineAssistant, see the [openai assistants API example](https://github.com/wirtualdev/wirtual-agents/blob/main/examples/voice-pipeline-agent/openai_assistant.py)
